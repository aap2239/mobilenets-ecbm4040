{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dc5d62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mobilenet_v3 import MobileNet\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7700268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85e0e812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from os import path\n",
    "\n",
    "# since we do not have access to the testing data\n",
    "# we need to take a number of images from the training data and use it instead\n",
    "NUM_CLASSES = 200\n",
    "NUM_TEST_IMAGES = 50 * NUM_CLASSES\n",
    "\n",
    "# define the path to the output training, validation, and testing HDF5 files\n",
    "TRAIN_HDF5 = \"/home/ecbm4040/mobilenets-ecbm4040/data/hdf5/train.hdf5\"\n",
    "VAL_HDF5 = \"/home/ecbm4040/mobilenets-ecbm4040/data/hdf5/val.hdf5\"\n",
    "TEST_HDF5 = \"/home/ecbm4040/mobilenets-ecbm4040/data/hdf5/test.hdf5\"\n",
    "\n",
    "# define the path to the dataset mean\n",
    "DATASET_MEAN = \"/home/ecbm4040/mobilenets-ecbm4040/data/output/tiny-image-net-200-mean.json\"\n",
    "\n",
    "# define the path to the output directory used for storing plots, classification reports, etc.\n",
    "OUTPUT_PATH = \"output\"\n",
    "MODEL_PATH = path.sep.join([OUTPUT_PATH, \"resnet_tinyimagenet.hdf5\"])\n",
    "FIG_PATH = path.sep.join([OUTPUT_PATH, \"resnet56_tinyimagenet.png\"])\n",
    "JSON_PATH = path.sep.join([OUTPUT_PATH, \"resnet56_tinyimagenet.json\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99d75d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "\n",
    "class ImageToArrayPreprocessor:\n",
    "    def __init__(self, data_format=None):\n",
    "        # store the image data format\n",
    "        self.data_format = data_format\n",
    "\n",
    "    def preprocess(self, image):\n",
    "        # apply the Keras utility function that correctly rearranges\n",
    "        # the dimensions of the image\n",
    "        return img_to_array(image, data_format=self.data_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ece07aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "class SimplePreprocessor:\n",
    "    def __init__(self, width, height, inter=cv2.INTER_AREA):\n",
    "        # store the target image width, height, and interpolation method used when resizing\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.inter = inter\n",
    "\n",
    "    def preprocess(self, image):\n",
    "        # resize the image to a fixed size, ignoring the aspect ratio\n",
    "        return cv2.resize(image, (self.width, self.height), interpolation=self.inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e836afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "class MeanPreprocessor:\n",
    "    def __init__(self, r_mean, g_mean, b_mean):\n",
    "        # store the Red, Green, and Blue channel averages across a training set\n",
    "        self.r_mean = r_mean\n",
    "        self.g_mean = g_mean\n",
    "        self.b_mean = b_mean\n",
    "\n",
    "    def preprocess(self, image):\n",
    "        # split the image into its respective Red, Green, and Blue channels\n",
    "        (B, G, R) = cv2.split(image.astype(\"float32\"))\n",
    "\n",
    "        # subtract the means for each channel\n",
    "        R -= self.r_mean\n",
    "        G -= self.g_mean\n",
    "        B -= self.b_mean\n",
    "\n",
    "        # merge the channels back together and return the image\n",
    "        return cv2.merge([B, G, R])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c5ace38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "import os\n",
    "\n",
    "\n",
    "class EpochCheckpoint(Callback):\n",
    "    def __init__(self, output_path, every=5, start_at=0):\n",
    "        # call the parent constructor\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        # store the base output path for the model, the number of\n",
    "        # epochs that must pass before the model is serialized to\n",
    "        # disk and the current epoch value\n",
    "        self.output_path = output_path\n",
    "        self.every = every\n",
    "        self.int_epoch = start_at\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs is None:\n",
    "            logs = {}\n",
    "\n",
    "        # check to see if the model should be serialized to disk\n",
    "        if (self.int_epoch + 1) % self.every == 0:\n",
    "            p = os.path.sep.join([self.output_path, \"epoch_{}.hdf5\".format(self.int_epoch + 1)])\n",
    "            self.model.save(p, overwrite=True)\n",
    "\n",
    "        # increment the internal epoch counter\n",
    "        self.int_epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d29ee5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import BaseLogger\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "class TrainingMonitor(BaseLogger):\n",
    "    def __init__(self, fig_path, json_path=None, start_at=0):\n",
    "        # store the output path for the figure, the path to the JSON serialized file, and the starting epoch\n",
    "        super(TrainingMonitor, self).__init__()\n",
    "        self.H = None\n",
    "        self.fig_path = fig_path\n",
    "        self.json_path = json_path\n",
    "        self.start_at = start_at\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        # initialize the history dictionary\n",
    "        if logs is None:\n",
    "            logs = {}\n",
    "        self.H = {}\n",
    "\n",
    "        # if the JSON history path exists, load the training history\n",
    "        if self.json_path is not None:\n",
    "            if os.path.exists(self.json_path):\n",
    "                self.H = json.loads(open(self.json_path).read())\n",
    "\n",
    "                # check to see if a starting epoch was supplied\n",
    "                if self.start_at > 0:\n",
    "                    # loop over the entries in the history log and\n",
    "                    # trim any entries that are past the starting\n",
    "                    # epoch\n",
    "                    for k in self.H.keys():\n",
    "                        self.H[k] = self.H[k][:self.start_at]\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # loop over the logs and update the loss, accuracy, etc. for the entire training process\n",
    "        if logs is None:\n",
    "            logs = {}\n",
    "        for (k, v) in logs.items():\n",
    "            cur_list = self.H.get(k, [])\n",
    "            cur_list.append(float(v))\n",
    "            self.H[k] = cur_list\n",
    "\n",
    "        # check to see if the training history should be serialized to file\n",
    "        if self.json_path is not None:\n",
    "            f = open(self.json_path, \"w\")\n",
    "            f.write(json.dumps(self.H))\n",
    "            f.close()\n",
    "\n",
    "        # ensure at least two epochs have passed before plotting (epoch starts at zero)\n",
    "        if len(self.H[\"loss\"]) > 1:\n",
    "            # plot the training loss and accuracy\n",
    "            epochs = np.arange(0, len(self.H[\"loss\"]))\n",
    "            plt.style.use(\"ggplot\")\n",
    "            plt.figure(figsize=(16, 10))\n",
    "            plt.plot(epochs, self.H[\"loss\"], label=\"train_loss\")\n",
    "            plt.plot(epochs, self.H[\"val_loss\"], label=\"val_loss\")\n",
    "            plt.plot(epochs, self.H[\"accuracy\"], label=\"train_acc\")\n",
    "            plt.plot(epochs, self.H[\"val_accuracy\"], label=\"val_acc\")\n",
    "            plt.title(f\"Training Loss and Accuracy [Epoch {len(self.H['loss'])}]\")\n",
    "            plt.xlabel(\"Epoch #\")\n",
    "            plt.ylabel(\"Loss/Accuracy\")\n",
    "            plt.legend()\n",
    "\n",
    "            # save the figure\n",
    "            plt.savefig(self.fig_path)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41dd1e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "\n",
    "class HDF5DatasetGenerator:\n",
    "    def __init__(self, db_path, batch_size, preprocessors=None, aug=None, binarize=True, classes=2):\n",
    "        # store the batch size, preprocessors, and data augmentor, whether the labels should be binarized,\n",
    "        # along with the total number of classes\n",
    "        self.batch_size = batch_size\n",
    "        self.preprocessors = preprocessors\n",
    "        self.aug = aug\n",
    "        self.binarize = binarize\n",
    "        self.classes = classes\n",
    "\n",
    "        # open the HDF5 database for reading and determine the total number of entries in the database\n",
    "        self.db = h5py.File(db_path, \"r\")\n",
    "        self.num_images = self.db[\"labels\"].shape[0]\n",
    "\n",
    "    def generator(self, passes=np.inf):\n",
    "        # initialize the epoch count\n",
    "        epochs = 0\n",
    "\n",
    "        # keep looping infinitely -- the model will stop once we have reach the desired number of epochs\n",
    "        while epochs < passes:\n",
    "            # loop over the HDF5 dataset\n",
    "            for i in np.arange(0, self.num_images, self.batch_size):\n",
    "                # extract the images and labels from the HDF dataset\n",
    "                images = self.db[\"images\"][i: i + self.batch_size]\n",
    "                labels = self.db[\"labels\"][i: i + self.batch_size]\n",
    "\n",
    "                # check to see if the labels should be binarized\n",
    "                if self.binarize:\n",
    "                    labels = to_categorical(labels, self.classes)\n",
    "\n",
    "                # check to see if our preprocessors are not None\n",
    "                if self.preprocessors is not None:\n",
    "                    # initialize the list of processed images\n",
    "                    proc_images = []\n",
    "\n",
    "                    # loop over the images\n",
    "                    for image in images:\n",
    "                        # loop over the preprocessors and apply each to the image\n",
    "                        for p in self.preprocessors:\n",
    "                            image = p.preprocess(image)\n",
    "\n",
    "                        # update the list of processed images\n",
    "                        proc_images.append(image)\n",
    "\n",
    "                    # update the images array to be the processed images\n",
    "                    images = np.array(proc_images)\n",
    "\n",
    "                # if the data augmentor exists, apply it\n",
    "                if self.aug is not None:\n",
    "                    (images, labels) = next(self.aug.flow(images, labels, batch_size=self.batch_size))\n",
    "                # yield a tuple of images and labels\n",
    "                yield images, labels\n",
    "                \n",
    "            # increment the total number of epochs\n",
    "            epochs += 1\n",
    "\n",
    "    def close(self):\n",
    "        # close the database\n",
    "        self.db.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9aa24e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def rank5_accuracy(preds, labels):\n",
    "    # initialize the rank-1 and rank-5 accuracies\n",
    "    rank1 = 0\n",
    "    rank5 = 0\n",
    "\n",
    "    # loop over the predictions and ground-truth labels\n",
    "    for (p, gt) in zip(preds, labels):\n",
    "        # sort the probabilities by their index in descending order\n",
    "        # so that the more confident guesses are at the front of the list\n",
    "        p = np.argsort(p)[::-1]\n",
    "\n",
    "        # check if the ground-truth label is in the top-5 predictions\n",
    "        if gt in p[:5]:\n",
    "            rank5 += 1\n",
    "\n",
    "        # check to see if the ground-truth is the #1 prediction\n",
    "        if gt == p[0]:\n",
    "            rank1 += 1\n",
    "\n",
    "    # compute the final rank-1 and rank-5 accuracies\n",
    "    rank1 /= float(len(preds))\n",
    "    rank5 /= float(len(preds))\n",
    "\n",
    "    # return a tuple of the rank-1 and rank-5 accuracies\n",
    "    return rank1, rank5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d9d9271",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import json\n",
    "import sys\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0948d200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the total number of epochs to train for along with the initial learning rate\n",
    "NUM_EPOCHS = 75\n",
    "INIT_LR = 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e429de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'model': MODEL_PATH,  # path to output model\n",
    "    'output': 'output',  # path to output directory (logs, plots, etc.)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b117dc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_decay(epoch):\n",
    "    # initialize the maximum number of epochs, base learning rate,\n",
    "    # and power of the polynomial\n",
    "    max_epochs = NUM_EPOCHS\n",
    "    base_lr = INIT_LR\n",
    "    power = 1.0\n",
    "\n",
    "    # compute the new learning rate based on polynomial decay\n",
    "    alpha = base_lr * (1 - (epoch / float(max_epochs))) ** power\n",
    "\n",
    "    # return the new learning rate\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a9402e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(\n",
    "    rotation_range=18, \n",
    "    zoom_range=0.15, \n",
    "    width_shift_range=0.2, \n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15, \n",
    "    horizontal_flip=True, \n",
    "    fill_mode=\"nearest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32f0ca8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R': 122.40461138237848, 'G': 114.18276671820746, 'B': 101.30663024902344}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = json.loads(open(DATASET_MEAN).read())\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bea34679",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = SimplePreprocessor(224, 224)\n",
    "mp = MeanPreprocessor(means[\"R\"], means[\"G\"], means[\"B\"])\n",
    "iap = ImageToArrayPreprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63a4579f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = HDF5DatasetGenerator(TRAIN_HDF5, 64, aug=aug, preprocessors=[sp, mp, iap], classes=NUM_CLASSES)\n",
    "val_gen = HDF5DatasetGenerator(VAL_HDF5, 64, preprocessors=[sp, mp, iap], classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53649942",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_path = os.path.sep.join([args[\"output\"], \"{}.png\".format(os.getpid())])\n",
    "json_path = os.path.sep.join([args[\"output\"], \"{}.json\".format(os.getpid())])\n",
    "callbacks = [\n",
    "    # TrainingMonitor(fig_path, json_path=json_path),\n",
    "    LearningRateScheduler(poly_decay)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7344c060",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet = MobileNet(\n",
    "    num_classes = NUM_CLASSES,\n",
    "    alpha = 1, \n",
    "    input_shape_ = (224, 224, 3)\n",
    ")\n",
    "\n",
    "mobilenet.build(input_shape = (None, 224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5260948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import top_k_categorical_accuracy\n",
    "from tensorflow.keras.losses import categorical_crossentropy, binary_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def top_5_accuracy(in_gt, in_pred):\n",
    "    return top_k_categorical_accuracy(in_gt, in_pred, k=5)\n",
    "\n",
    "mobilenet.compile(\n",
    "    optimizer = Adam(lr=INIT_LR), \n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['categorical_accuracy', top_5_accuracy]\n",
    ")\n",
    "#mobilenet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0ce5a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"actor\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 112, 112, 32)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d (DepthwiseC (None, 112, 112, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 112, 112, 64)      2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_1 (Depthwis (None, 56, 56, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 56, 56, 128)       8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_2 (Depthwis (None, 56, 56, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 56, 56, 128)       16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "re_lu_6 (ReLU)               (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_3 (Depthwis (None, 28, 28, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "re_lu_7 (ReLU)               (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 256)       33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "re_lu_8 (ReLU)               (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_4 (Depthwis (None, 28, 28, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "re_lu_9 (ReLU)               (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 256)       65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "re_lu_10 (ReLU)              (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_5 (Depthwis (None, 14, 14, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "re_lu_11 (ReLU)              (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 14, 14, 512)       131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "re_lu_12 (ReLU)              (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_6 (Depthwis (None, 14, 14, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "re_lu_13 (ReLU)              (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 14, 14, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "re_lu_14 (ReLU)              (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_7 (Depthwis (None, 14, 14, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "re_lu_15 (ReLU)              (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 14, 14, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "re_lu_16 (ReLU)              (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_8 (Depthwis (None, 14, 14, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "re_lu_17 (ReLU)              (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 14, 14, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "re_lu_18 (ReLU)              (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_9 (Depthwis (None, 14, 14, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "re_lu_19 (ReLU)              (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 14, 14, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "re_lu_20 (ReLU)              (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_10 (Depthwi (None, 14, 14, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "re_lu_21 (ReLU)              (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 14, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "re_lu_22 (ReLU)              (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_11 (Depthwi (None, 7, 7, 512)         5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "re_lu_23 (ReLU)              (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 7, 7, 1024)        525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "re_lu_24 (ReLU)              (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_12 (Depthwi (None, 7, 7, 1024)        10240     \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "re_lu_25 (ReLU)              (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 7, 7, 1024)        1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "re_lu_26 (ReLU)              (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 7)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 200)               1600      \n",
      "=================================================================\n",
      "Total params: 3,241,408\n",
      "Trainable params: 3,219,520\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x7fa1f1d473c8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobilenet.make()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d78b211",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(mobilenet, to_file='mobilenet.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de41e4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Epoch 1/75\n",
      " 154/1406 [==>...........................] - ETA: 13:11 - loss: 5.3549 - categorical_accuracy: 0.0047 - top_5_accuracy: 0.0224"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] training network...\")\n",
    "H = mobilenet.fit(\n",
    "    train_gen.generator(),\n",
    "    steps_per_epoch=train_gen.num_images // 64,\n",
    "    validation_data=val_gen.generator(),\n",
    "    validation_steps=val_gen.num_images // 64,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    max_queue_size=10,\n",
    "    callbacks=callbacks, \n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8304b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
